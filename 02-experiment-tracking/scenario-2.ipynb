{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scenario 2: A cross-functional team with one data scientist working on an ML model\n",
    "\n",
    "\n",
    "MLflow setup:\n",
    "- tracking server: yes, local server\n",
    "- backend store: sqlite database\n",
    "- artifacts store: local filesystem\n",
    "\n",
    "The experiments can be explored locally by accessing the local tracking server.\n",
    "\n",
    "To run this example you need to launch the mlflow server locally by running the following command in your terminal:\n",
    "\n",
    "`mlflow server --backend-store-uri sqlite:///backend.db`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "\n",
    "\n",
    "mlflow.set_tracking_uri(\"http://127.0.0.1:5000\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tracking URI: 'http://127.0.0.1:5000'\n"
     ]
    }
   ],
   "source": [
    "print(f\"tracking URI: '{mlflow.get_tracking_uri()}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/05/25 22:10:50 INFO mlflow.tracking.fluent: Experiment with name 'my-experiment-1' does not exist. Creating a new experiment.\n",
      "\u001b[31m2025/05/25 22:10:52 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "default artifacts URI: 'mlflow-artifacts:/1/b74e44e4bf584698bceedfac56f0f19e/artifacts'\n",
      "🏃 View run victorious-pug-771 at: http://127.0.0.1:5000/#/experiments/1/runs/b74e44e4bf584698bceedfac56f0f19e\n",
      "🧪 View experiment at: http://127.0.0.1:5000/#/experiments/1\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "mlflow.set_experiment(\"my-experiment-1\")\n",
    "\n",
    "with mlflow.start_run():\n",
    "\n",
    "    X, y = load_iris(return_X_y=True)\n",
    "\n",
    "    params = {\"C\": 0.1, \"random_state\": 42}\n",
    "    mlflow.log_params(params)\n",
    "\n",
    "    lr = LogisticRegression(**params).fit(X, y)\n",
    "    y_pred = lr.predict(X)\n",
    "    mlflow.log_metric(\"accuracy\", accuracy_score(y, y_pred))\n",
    "\n",
    "    mlflow.sklearn.log_model(lr, artifact_path=\"models\")\n",
    "    print(f\"default artifacts URI: '{mlflow.get_artifact_uri()}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.list_experiments()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interacting with the model registry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlflow.tracking import MlflowClient\n",
    "\n",
    "\n",
    "client = MlflowClient(\"http://127.0.0.1:5000\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'MlflowClient' object has no attribute 'list_run_infos'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m run_id = \u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlist_run_infos\u001b[49m(experiment_id=\u001b[33m'\u001b[39m\u001b[33m1\u001b[39m\u001b[33m'\u001b[39m)[\u001b[32m0\u001b[39m].run_id\n\u001b[32m      2\u001b[39m mlflow.register_model(\n\u001b[32m      3\u001b[39m     model_uri=\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mruns:/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrun_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m/models\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m      4\u001b[39m     name=\u001b[33m'\u001b[39m\u001b[33miris-classifier\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m      5\u001b[39m )\n",
      "\u001b[31mAttributeError\u001b[39m: 'MlflowClient' object has no attribute 'list_run_infos'"
     ]
    }
   ],
   "source": [
    "run_id = client.list_run_infos(experiment_id='1')[0].run_id\n",
    "mlflow.register_model(\n",
    "    model_uri=f\"runs:/{run_id}/models\",\n",
    "    name='iris-classifier'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0848c9d6c7d415ad6c477ff7ff8e98694d1a4aa96d0deee89244642e6b630036"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
